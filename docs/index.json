
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    [{"authors":null,"categories":null,"content":"I‚Äôm Tomislav ƒêuriƒçiƒá, a Senior Machine Learning Researcher at Know Center Research in Graz, Austria. I‚Äôm pursuing my PhD at Graz University of Technology, focusing on ‚ÄúBeyond-Accuracy Optimization in Social-based Recommender Systems.‚Äù I work primarily in the Fair AI Lab, developing advanced AI solutions for industry and research applications.\nMy work bridges academic research with industry applications. I‚Äôve developed recommendation systems for student job platforms, time-series forecasting solutions for automotive inventory planning, and outlier detection systems for retail optimization. In my research, I explore graph neural networks, trust-based recommender systems, and evaluation metrics beyond simple accuracy, publishing findings in venues like RecSys, ECAI, and ASONAM. Throughout my career, I‚Äôve led both research-focused and industry-oriented projects, including initiatives funded by the European Union.\nMy research interests include recommender systems, graph neural networks, trust networks, and user modeling. I‚Äôm currently focused on integrating large language models into immersive AR/VR environments for industrial applications, creating digital twins that enhance machine operation and training.\nI earned my MSc and BSc in Software Engineering and Information Systems from the University of Zagreb‚Äôs Faculty of Electrical Engineering and Computing. Outside of work, I enjoy playing basketball with the Gold Diggers, jogging, and attending music events.\n","date":1727740800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1727740800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"I‚Äôm Tomislav ƒêuriƒçiƒá, a Senior Machine Learning Researcher at Know Center Research in Graz, Austria. I‚Äôm pursuing my PhD at Graz University of Technology, focusing on ‚ÄúBeyond-Accuracy Optimization in Social-based Recommender Systems.","tags":null,"title":"Tomislav ƒêuriƒçiƒá","type":"authors"},{"authors":["Tomislav ƒêuriƒçiƒá","Peter M√ºllner","Nicole Weidinger","Neven ElSayed","Dominik Kowald","Eduardo Veas"],"categories":null,"content":"","date":1727740800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1727740800,"objectID":"2efba6eda71111915b8e777dfbc9d1c6","permalink":"https://tduricic.me/publication/2024_ecai/","publishdate":"2024-09-01T00:00:00Z","relpermalink":"/publication/2024_ecai/","section":"publication","summary":"This demo paper presents an AI-powered immersive assistance system that helps users perform complex industrial tasks. Our VR-based digital twin simulates complex machinery, and by processing expert video and speech with AI models, it provides step-by-step guidance. This proof-of-concept demonstrates potential benefits like reduced cognitive load, increased productivity, and enhanced safety in industrial environments.","tags":["Immersive Analytics","Industrial Assistance","Virtual Reality","AI Assistants","Digital Twins","Human-Computer Interaction","Large Language Models"],"title":"AI-Powered Immersive Assistance for Interactive Task Execution in Industrial Environments","type":"publication"},{"authors":["Tomislav ƒêuriƒçiƒá","Dominik Kowald","Emanuel Laciƒá","Elisabeth Lex"],"categories":null,"content":"","date":1702944000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1702944000,"objectID":"e0cb397b126dd94cea3ef73b505fe660","permalink":"https://tduricic.me/publication/2023_frontiers/","publishdate":"2023-12-19T00:00:00Z","relpermalink":"/publication/2023_frontiers/","section":"publication","summary":"Recommender systems are vital to online platforms, with Graph Neural Network (GNN) approaches showing excellent accuracy. However, beyond-accuracy metrics like diversity, serendipity, and fairness significantly impact user satisfaction. This review examines these dimensions in GNN-based recommenders, analyzing recent developments that balance accuracy with these broader objectives. We explore how various model development stages‚Äîfrom data preprocessing to training methodologies‚Äîaffect these metrics. The paper addresses practical challenges in maintaining high accuracy while enhancing diversity, serendipity, and fairness, and outlines future research directions for more holistic GNN-based recommender systems. Our contribution lies in providing a comprehensive understanding of the multidimensional considerations essential to effective recommender system design.","tags":["Recommender Systems","Graph Neural Networks","Diversity","Serendipity","Fairness","Beyond-Accuracy Metrics","Machine Learning"],"title":"Beyond-Accuracy: A Review on Diversity, Serendipity, and Fairness in Recommender Systems Based on Graph Neural Networks","type":"publication"},{"authors":null,"categories":null,"content":"Project Overview (October 2023 ‚Äì June 2026) The DDIA (Data Driven Immersive Analytics) project is a COMET-funded initiative aimed at improving immersive analytics and digital twin interactions for industrial applications. Digital twins‚Äîinteractive digital representations of real-world objects‚Äîare vital tools for remote collaboration, operational support, and training. However, the usability and intuitiveness of current immersive methods often fall short, creating barriers to effective interaction.\nDetailed project information can be found on the official DDIA project website and the FFG COMET factsheet.\nObjectives DDIA‚Äôs key goals are:\nEnhancing immersive interaction paradigms and analytics. Improving remote collaboration and training through intuitive AR/VR interfaces. Personalizing user experiences by integrating physiological sensing data. Technical Challenges Key challenges addressed in this project include:\nCreating seamless and intuitive interactions with digital twins in immersive environments Integrating large language models with real-time AR/VR applications while maintaining performance Developing effective multimodal interfaces combining speech, gesture, and traditional input methods Processing and utilizing physiological data to adapt interfaces in real-time Ensuring cross-platform compatibility between different AR/VR hardware ecosystems Balancing computational requirements of AI assistants with the performance constraints of mobile VR/AR devices Technologies and Methods In DDIA, advanced AI and immersive technologies include:\nLarge Language Models: Integration of GPT (OpenAI), LLaMA (Meta), Claude (Anthropic), DeepSeek, and Qwen (Alibaba) to build intelligent AI assistants for machine operation and training. Unity-based AR/VR Development: Interfaces developed for Meta Quest and Microsoft HoloLens to facilitate immersive, interactive experiences with digital twins. Speech Interaction: OpenAI Whisper for speech-to-text and text-to-speech, enabling natural voice-driven interactions. Physiological Sensing: Capturing physiological data to personalize interactions and enhance user comfort and efficiency. Meta Aria Glasses: Expert operation data collection to refine future training and interaction paradigms. Personal Contribution My involvement in DDIA includes:\nDesigning and developing immersive AR/VR interfaces in Unity for Meta Quest and Microsoft HoloLens. Implementing AI assistants powered by advanced large language models. Integrating OpenAI Whisper to provide robust and intuitive speech interaction. Analyzing immersive and physiological data to enhance personalized interactions and improve collaborative workflows. Through these activities, DDIA aims to deliver user-friendly, personalized digital experiences, significantly advancing remote collaboration, support, and training in industrial settings.\n","date":1696118400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1696118400,"objectID":"ee544a2bc2e4ca66d0636e73377c5c1c","permalink":"https://tduricic.me/project/ddia/","publishdate":"2023-10-01T00:00:00Z","relpermalink":"/project/ddia/","section":"project","summary":"Research project enhancing digital twin interactions and immersive analytics using personalized AI, AR/VR interfaces, and physiological sensing for improved remote collaboration, support, and training in industry.","tags":["Digital Twins","Immersive Analytics","Large Language Models","Unity","Meta Quest","Meta Aria","Microsoft HoloLens","Personalization","Physiological Sensing","Embodied Interaction","AI Assistants","Machine Learning","Virtual Reality","Augmented Reality"],"title":"DDIA - Data Driven Immersive Analytics","type":"project"},{"authors":["Mario Lovriƒá","Tomislav ƒêuriƒçiƒá","Hussain Hussain","Bono Luciƒá","Roman Kern"],"categories":null,"content":"","date":1689811200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1689811200,"objectID":"49775a09f375b692204cbafc46429dab","permalink":"https://tduricic.me/publication/2023_chemrxiv/","publishdate":"2023-07-20T00:00:00Z","relpermalink":"/publication/2023_chemrxiv/","section":"publication","summary":"PyChemFlow is a Python library for automated, reproducible data pre-processing that leverages transformer objects built on minimal dependencies. It enables one-line execution with train-validation splits, persistent storage of transformers and metadata, and customizable data manipulation steps, making it ideal for applications requiring strict reproducibility.","tags":["Data Preprocessing","Chemical Informatics","Reproducibility","Pipeline Automation","Scientific Computing","Python Libraries","Machine Learning","Data Pipeline"],"title":"PyChemFlow: an automated pre-processing pipeline in Python for reproducible machine learning on chemical data","type":"publication"},{"authors":["Emanuel Laciƒá","Tomislav ƒêuriƒçiƒá","Leon Fadljeviƒá","Dieter Theiler","Dominik Kowald"],"categories":null,"content":"","date":1689811200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1689811200,"objectID":"483541e6a4c35704d852ff9d170c1ffa","permalink":"https://tduricic.me/publication/2023_ecir/","publishdate":"2023-07-20T00:00:00Z","relpermalink":"/publication/2023_ecir/","section":"publication","summary":"Uptrendz is a multi-domain recommendation platform offering real-time, API-centric recommendations across varied applications. Demonstrated with both MovieLens-100k movie recommendations and entrepreneurial start-up founding use cases, it distinguishes between item and system-level domains for flexible customization, deployment and evaluation. Code and documentation available on GitHub.","tags":["Recommender Systems","Multi-Domain","API-Centric Design","Real-Time Analytics","System Architecture","Software Engineering"],"title":"Uptrendz: API-Centric Real-time Recommendations in Multi-Domain Settings","type":"publication"},{"authors":null,"categories":null,"content":"Project Overview (January 2023 ‚Äì December 2023) The AVL Research Project was a collaborative effort between Graz University of Technology and AVL List GmbH, focusing on developing intelligent methods to support fault tree construction for automotive diagnostics. The project‚Äôs success led directly to securing additional funding through the FFG proposal ‚ÄúHybridAIR,‚Äù extending research activities for an additional three years.\nResearch Objectives Address the increasing complexity in automotive systems by automating the traditionally manual fault tree analysis (FTA) process. Enhance diagnostic accuracy and efficiency using sequential recommendation algorithms. Leverage contextual insights by incorporating text embeddings derived from pre-trained language models. Key Contributions Reformulated fault tree creation as a sequential recommendation task, significantly improving fault diagnosis accuracy. Developed an innovative framework integrating sequential recommendation and contextual embeddings, preserving expert oversight while reducing manual effort. Conducted comprehensive experiments validating model effectiveness, leading to a publication submitted to the high-impact journal Reliability Engineering \u0026amp; System Safety. Outcomes and Impact Demonstrated significant improvements in fault tree accuracy and construction efficiency, validated on AVL‚Äôs extensive automotive diagnostic dataset. Provided a scalable and flexible methodology applicable to other safety-critical engineering domains beyond automotive diagnostics. Played a key role in securing long-term research funding (FFG HybridAIR) to continue advancing diagnostic capabilities and machine learning integration. Personal Role Acted as the main contributor and senior researcher on the project, leading both the methodological development and experimental evaluation. Collaborated closely with AVL experts and university researchers to align research outputs with practical automotive industry requirements. Authored and submitted the key research publication outlining the developed methods, experimental validation, and future research directions. ","date":1672531200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1672531200,"objectID":"88db7bfc3a0f97b0c5deca40a97d7db4","permalink":"https://tduricic.me/project/avl/","publishdate":"2023-01-01T00:00:00Z","relpermalink":"/project/avl/","section":"project","summary":"Research collaboration between Graz University of Technology and AVL List GmbH focused on applying sequential recommendation methods and text embeddings to automate and enhance automotive diagnostic fault tree construction.","tags":["Automotive Diagnostics","Fault Tree Analysis","Sequential Recommendation","Text Embeddings","Machine Learning","Automotive","Recommender Systems"],"title":"AVL Research Project: Intelligent Fault Tree Construction for Automotive Diagnostics","type":"project"},{"authors":["Tomislav ƒêuriƒçiƒá","Dominik Kowald","Markus Schedl","Elisabeth Lex"],"categories":null,"content":"","date":1642550400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1642550400,"objectID":"54e549669fc2e54a1d5fd5d0de3149d4","permalink":"https://tduricic.me/publication/2021_asonam/","publishdate":"2022-01-19T00:00:00Z","relpermalink":"/publication/2021_asonam/","section":"publication","summary":"This study examines homophily on Last.fm based on users' preferences for mainstream, novel, or diverse music content. We compare friendship connections to listening profiles and evaluate these features for link prediction. Results show that friends share similar artist preferences, with diversity being a stronger predictor of friendship than mainstream or novelty preferences. While high-novelty users show strong homophily, they have lower artist profile similarity. Mainstream/novel/diverse features perform comparably to artist profiles in link prediction, with combined features yielding best results‚Äîthough adding no value when graph-based features are available. These insights inform music recommendation, user modeling, and cold-start link prediction.","tags":["Homophily","Link Prediction","Music Recommendations","User Preferences","Diversity","Social Networks","Novelty","Machine Learning"],"title":"My friends also prefer diverse music: homophily and link prediction with user preferences for mainstream, novelty, and diversity in music","type":"publication"},{"authors":[],"categories":null,"content":"","date":1638361800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1638361800,"objectID":"60cfb866d2847acdee0cc24175e2e4ec","permalink":"https://tduricic.me/talk/presentation-at-the-ebdvf-2021/","publishdate":"2021-12-01T14:00:00Z","relpermalink":"/talk/presentation-at-the-ebdvf-2021/","section":"event","summary":"I gave a presentation on the topic of \"Big Data and AI for the Financial Sector - challenges and opportunities\" at the EBDVF 2021","tags":[],"title":"Presentation at the EBDVF 2021","type":"event"},{"authors":[],"categories":null,"content":"","date":1637661600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1637661600,"objectID":"26976c57cbbf21122f80f5246a8f1e9a","permalink":"https://tduricic.me/talk/panel-discussion-at-zagreb-connect-2021/","publishdate":"2021-11-23T10:00:00Z","relpermalink":"/talk/panel-discussion-at-zagreb-connect-2021/","section":"event","summary":"I participated in a panel discussion at Zagreb Connect, where we discussed building successful and sustainable startup ecosystems.","tags":[],"title":"Panel Discussion at Zagreb Connect 2021","type":"event"},{"authors":["Hussain Hussain","Tomislav ƒêuriƒçiƒá","Elisabeth Lex","Denis Heliƒá","Roman Kern"],"categories":null,"content":"","date":1635206400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1635206400,"objectID":"a92c57403ec07c70a84b498266ccde81","permalink":"https://tduricic.me/publication/2021_ans/","publishdate":"2021-10-26T00:00:00Z","relpermalink":"/publication/2021_ans/","section":"publication","summary":"This study investigates how community structure and homophily influence Graph Neural Networks (GNNs) in semi-supervised node classification tasks. By systematically modifying eight datasets and measuring GNN performance with and without these structural properties, we demonstrate their significant impact on classification accuracy and reveal insights about their interaction. We introduce an information-theoretic metric to quantify community-label correlation, providing practical guidelines for model selection based on graph structure. Our findings enhance understanding of GNN capabilities and improve model selection for semi-supervised node classification tasks.","tags":["Graph Neural Networks","Community Structure","Homophily","Semi-Supervised Learning","Node Classification","Network Science","Machine Learning"],"title":"The interplay between communities and homophily in semi-supervised classification using graph neural networks","type":"publication"},{"authors":["Oana Inel","Tomislav ƒêuriƒçiƒá","Harmanpreet Kaur","Elisabeth Lex","Nava Tintarev"],"categories":null,"content":"","date":1632700800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1632700800,"objectID":"6f2c104bcaf4d62cf19306d64cac1678","permalink":"https://tduricic.me/publication/2021_frontiers/","publishdate":"2021-09-27T00:00:00Z","relpermalink":"/publication/2021_frontiers/","section":"publication","summary":"This study introduces natural language explanations designed to promote more thoughtful reasoning about online videos and increase awareness of potentially biased or misleading content. We developed an end-to-end pipeline that extracts reflection triggers about video sources, topics, emotions, and sentiment to help users actively evaluate video usefulness. Our between-subjects study examining controversial topics reveals that users' alignment with video messages significantly impacts perceived usefulness. While explanations were rated highly, they didn't alter overall usefulness perceptions compared to videos alone. Notably, users with extreme negative alignment found videos less useful regardless of explanations and were more confident in their assessments. We interpret these findings through cognitive dissonance theory and propose design implications for explanations aimed at raising awareness about online deception.","tags":["Explanations","User Behavior","Content Assessment","Information Quality"],"title":"Design Implications for Explanations: A Case Study on Supporting Reflective Assessment of Potentially Misleading Videos","type":"publication"},{"authors":["Hussain Hussain","Tomislav ƒêuriƒçiƒá","Elisabeth Lex","Denis Heliƒá","Markus Strohmaier","Roman Kern"],"categories":null,"content":"","date":1630195200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1630195200,"objectID":"7e64e881d212883ecb074b3ba7c219d6","permalink":"https://tduricic.me/publication/2021_ht/","publishdate":"2021-08-29T00:00:00Z","relpermalink":"/publication/2021_ht/","section":"publication","summary":"Graph neural networks (GNNs) are vulnerable to adversarial attacks, but most attack methods require node attribute information. This paper introduces Structack, an uninformed attack strategy that exploits only graph structural properties without needing node attributes. By targeting links between nodes with low similarity and low centrality, Structack approaches the effectiveness of informed attacks while being computationally more efficient. The findings demonstrate that structural knowledge alone can significantly degrade GNN performance, contributing to the development of more robust graph-based machine learning methods.","tags":["Graph Neural Networks","Adversarial Attacks","Network Security","Node Centrality","Graph Structure","Robustness"],"title":"Structack: Structure-based Adversarial Attacks on Graph Neural Networks","type":"publication"},{"authors":["Mario Lovriƒá","Tomislav ƒêuriƒçiƒá","Han T.N. Tran","Hussain Hussain","Emanuel Laciƒá","Morten A. Rasmussen","Roman Kern"],"categories":null,"content":"","date":1626912000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1626912000,"objectID":"2d9c7c14331fb3edce032c22151d9a2f","permalink":"https://tduricic.me/publication/2021_mdpi/","publishdate":"2021-07-22T00:00:00Z","relpermalink":"/publication/2021_mdpi/","section":"publication","summary":"This study examines three unsupervised dimensionality reduction techniques (PCA, UMAP, and VAEs) for toxicology classification tasks. The research compares these embedding methods against standard molecular fingerprint models and explores transfer learning by training embedders on external chemical compound datasets. By testing various embedding dimensions and external dataset sizes, the findings demonstrate that UMAP can effectively complement established techniques like PCA and VAE for pre-compression in toxicology. However, VAE's generative approach shows superior performance in pre-compression for classification accuracy.","tags":["Transfer Learning","Dimensionality Reduction","Molecular Fingerprints","Variational Autoencoders","UMAP","Chemical Informatics","Machine Learning"],"title":"Should We Embed in Chemistry? A Comparison of Unsupervised Transfer Learning with PCA, UMAP, and VAE on Molecular Fingerprints","type":"publication"},{"authors":["Tomislav ƒêuriƒçiƒá","Volker Seiser","Elisabeth Lex"],"categories":null,"content":"","date":1625270400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1625270400,"objectID":"ac3c38ff2a6c33dc0c99f46578914aa5","permalink":"https://tduricic.me/publication/2021_ic2s2/","publishdate":"2021-07-03T00:00:00Z","relpermalink":"/publication/2021_ic2s2/","section":"publication","summary":"This study examines how language in YouTube comments changes after videos are shared on Reddit's conspiracy forum. Analyzing 859 videos and 180,000+ comments, we found YouTube comments adopt linguistic patterns similar to r/conspiracy after Reddit exposure, evidenced by reduced text distribution distances. While sentiment remains unchanged, vocabulary measurably shifts toward conspiracy forum discourse, demonstrating cross-platform influence on user language.","tags":["Cross-Platform Analysis","Social Media","Text Analysis","User Behavior","Information Diffusion","Conspiracy Theories"],"title":"Cross-platform analysis of user comments in YouTube videos linked on Reddit‚Äôs conspiracy theory forum","type":"publication"},{"authors":["Hussain Hussain","Tomislav ƒêuriƒçiƒá","Elisabeth Lex","Roman Kern","Denis Heliƒá"],"categories":null,"content":"","date":1609804800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609804800,"objectID":"7abc4e39dd65184fd8018f894d84fb90","permalink":"https://tduricic.me/publication/2020_complenet/","publishdate":"2021-01-05T00:00:00Z","relpermalink":"/publication/2020_complenet/","section":"publication","summary":"This study examines how community structures in graphs affect Graph Neural Networks (GNNs) in node classification tasks. Through experiments on six datasets, researchers found that community structures significantly impact GNN performance. When nodes in a community mostly share the same label, disrupting the community structure dramatically reduces performance. Conversely, when labels don't correlate with communities, graph structure becomes less relevant and simple feature-based models perform comparably. The research provides insights and guidelines for selecting appropriate models based on graph structure characteristics.","tags":["Graph Neural Networks","Community Detection","Semi-Supervised Learning","Node Classification","Community Structure","Network Analysis","Machine Learning"],"title":"On the Impact of Communities on Semi-supervised Classification Using Graph Neural Networks","type":"publication"},{"authors":["Tomislav ƒêuriƒçiƒá","Âê≥ÊÅ©ÈÅî"],"categories":["Demo","ÊïôÁ®ã"],"content":"import libr print(\u0026#39;hello\u0026#39;) Overview The Wowchemy website builder for Hugo, along with its starter templates, is designed for professional creators, educators, and teams/organizations - although it can be used to create any kind of site The template can be modified and customised to suit your needs. It‚Äôs a good platform for anyone looking to take control of their data and online identity whilst having the convenience to start off with a no-code solution (write in Markdown and customize with YAML parameters) and having flexibility to later add even deeper personalization with HTML and CSS You can work with all your favourite tools and apps with hundreds of plugins and integrations to speed up your workflows, interact with your readers, and much more Get Started üëâ Create a new site üìö Personalize your site üí¨ Chat with the Wowchemy community or Hugo community üê¶ Twitter: @wowchemy @GeorgeCushen #MadeWithWowchemy üí° Request a feature or report a bug for Wowchemy ‚¨ÜÔ∏è Updating Wowchemy? View the Update Tutorial and Release Notes Crowd-funded open-source software To help us develop this template and software sustainably under the MIT license, we ask all individuals and businesses that use it to help support its ongoing maintenance and development via sponsorship.\n‚ù§Ô∏è Click here to become a sponsor and help support Wowchemy‚Äôs future ‚ù§Ô∏è As a token of appreciation for sponsoring, you can unlock these awesome rewards and extra features ü¶Ñ‚ú®\nEcosystem Hugo Academic CLI: Automatically import publications from BibTeX Inspiration Check out the latest demo of what you‚Äôll get in less than 10 minutes, or view the showcase of personal, project, and business sites.\nFeatures Page builder - Create anything with widgets and elements Edit any type of content - Blog posts, publications, talks, slides, projects, and more! Create content in Markdown, Jupyter, or RStudio Plugin System - Fully customizable color and font themes Display Code and Math - Code highlighting and LaTeX math supported Integrations - Google Analytics, Disqus commenting, Maps, Contact Forms, and more! Beautiful Site - Simple and refreshing one page design Industry-Leading SEO - Help get your website found on search engines and social media Media Galleries - Display your images and videos with captions in a customizable gallery Mobile Friendly - Look amazing on every screen with a mobile friendly version of your site Multi-language - 34+ language packs including English, ‰∏≠Êñá, and Portugu√™s Multi-user - Each author gets their own profile page Privacy Pack - Assists with GDPR Stand Out - Bring your site to life with animation, parallax backgrounds, and scroll effects One-Click Deployment - No servers. No databases. Only files. Themes Wowchemy and its templates come with automatic day (light) and night (dark) mode built-in. Alternatively, visitors can choose their preferred mode - click the moon icon in the top right of the Demo to see it in action! Day/night mode can also be disabled by the site admin in params.toml.\nChoose a stunning theme and font for your site. Themes are fully customizable.\nLicense Copyright 2016-present George Cushen.\nReleased under the MIT license.\n","date":1607817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607817600,"objectID":"279b9966ca9cf3121ce924dca452bb1c","permalink":"https://tduricic.me/post/getting-started/","publishdate":"2020-12-13T00:00:00Z","relpermalink":"/post/getting-started/","section":"post","summary":"Welcome üëã We know that first impressions are important, so we've populated your new site with some initial content to help you get familiar with everything in no time.","tags":null,"title":"Welcome to Wowchemy, the website builder for Hugo","type":"post"},{"authors":["Tomislav ƒêuriƒçiƒá","Hussain Hussain","Emanuel Laciƒá","Dominik Kowald","Denis Heliƒá","Elisabeth Lex"],"categories":null,"content":"","date":1600300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1600300800,"objectID":"e98359b53cf817fc34a3611b362966f5","permalink":"https://tduricic.me/publication/2020_ismis/","publishdate":"2020-09-17T00:00:00Z","relpermalink":"/publication/2020_ismis/","section":"publication","summary":"In this work, we study the utility of graph embeddings to generate latent user representations for trust-based collaborative filtering. In a cold-start setting, on three publicly available datasets, we evaluate approaches from four method families - (i) factorization-based, (ii) random walk-based, (iii) deep learning-based, and (iv) the Large-scale Information Network Embedding (LINE) approach. We find that across the four families, random-walk-based approaches consistently achieve the best accuracy. Besides, they result in highly novel and diverse recommendations. Furthermore, our results show that the use of graph embeddings in trust-based collaborative filtering significantly improves user coverage.","tags":["Recommender Systems","Graph Embeddings","Trust Networks","Collaborative Filtering","Cold-Start Problem","Empirical Analysis","Machine Learning"],"title":"Empirical Comparison of Graph Embeddings for Trust-Based Collaborative Filtering","type":"publication"},{"authors":null,"categories":null,"content":"Project Overview (September 2020 ‚Äì August 2023) The COGSTEPS project, funded under the ERASMUS+ Strategic Partnerships for Higher Education, aimed to bridge the gap between academia and the startup ecosystem. Coordinated by the University of Zagreb, it involved partners from Austria, Slovenia, and Croatia. The project‚Äôs key goals included fostering entrepreneurial mindsets among researchers, launching more university spin-offs, and creating a regional hub for innovation.\nThis project marked the first successful ERASMUS+ proposal from Know Center Research, securing approximately ‚Ç¨350,000 funding for six partners over three years.\nMain Objectives Change perceptions about startups within academic and scientific communities. Increase the number of startups and spin-offs emerging from universities. Develop entrepreneurial, transferable, and transversal skills among students, researchers, and academics. Create an innovative digital platform for matchmaking and startup education. Implementation and Activities Development and integration of the ScaR recommender system into the COGSTEPS platform for personalized content and matchmaking recommendations. Organized educational bootcamps and workshops across Graz, Zagreb, and Ljubljana. Conducted dissemination events including a major event at PODIM Conference in Maribor and a final demonstration day in Graz. Results \u0026amp; Impact Developed the COGSTEPS platform for networking, education, and matchmaking between researchers, startup founders, mentors, incubators, and investors. Successfully implemented multiple educational programs tailored to different stages of startup development (from idea validation to growth). Enhanced regional collaboration, significantly contributing to the development of the startup ecosystem within academic institutions. Personal Contribution Acted as software and ML engineer at Know Center Research, integrating the ScaR recommender system into the web platform. Led project management and startup mentoring efforts at Graz University of Technology, managing a small internal team. Coordinated international collaboration, event planning, and participant engagement, directly contributing to the project‚Äôs successful delivery. ","date":1598918400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598918400,"objectID":"0e32d028cd492f013ee0ec6f4959d53f","permalink":"https://tduricic.me/project/cogsteps/","publishdate":"2020-09-01T00:00:00Z","relpermalink":"/project/cogsteps/","section":"project","summary":"ERASMUS+ project designed to bridge academia and the startup ecosystem, developing a platform and educational programs to foster innovation and entrepreneurial skills among researchers and scientists.","tags":["Startup Education","Recommender Systems","Matchmaking","Project Management","Entrepreneurship","Machine Learning","Real-Time Recommendations"],"title":"COGSTEPS - Crossing the Gap: Startup Education and Support for Researchers","type":"project"},{"authors":null,"categories":null,"content":"Project Overview (January 2020 ‚Äì December 2023) The DDAI Comet Module is a research initiative that integrates privacy-preserving, explainable, and verifiable techniques into data-driven AI systems. Funded through the COMET programme (Competence Centers for Excellent Technologies), the project combines machine learning, cryptography, and interpretability methods to deliver secure and understandable AI solutions.\nThe project involves collaboration between the Know Center Research, Graz University of Technology, and numerous international academic and industrial partners. Additional details can be found on the DDAI project website.\nMy Contribution My PhD research was partly funded by the DDAI project, enabling me to focus on explainability in recommender systems, graph-based machine learning, and modeling user behavior and preferences. My work specifically involved:\nResearching methods for enhancing interpretability and transparency in recommender systems. Evaluating novel approaches to graph embeddings and graph neural networks. Modeling user behavior and preferences to improve the accuracy and relevance of recommendations, particularly exploring aspects such as homophily and diversity. Collaborative research within interdisciplinary teams. I authored several key publications and contributed significantly to additional studies within the project. Please find the full publication list below.\n","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577836800,"objectID":"3e71b6a8a8c0d82653e1c23fae8bdc22","permalink":"https://tduricic.me/project/ddai/","publishdate":"2020-01-01T00:00:00Z","relpermalink":"/project/ddai/","section":"project","summary":"Research module developing privacy-preserving, verifiable, and explainable AI solutions, combining cryptography, explainable AI, and machine learning, contributing to both academic knowledge and practical industry applications.","tags":["Explainable AI","Machine Learning","Graph Neural Networks","Recommender Systems","User Modeling","Privacy-Preserving AI"],"title":"DDAI - Explainable, Verifiable, and Privacy-Preserving Data-Driven AI","type":"project"},{"authors":["Emanuel Laciƒá","Markus Reiter-Haas","Tomislav ƒêuriƒçiƒá","Valentin Slawicek","Elisabeth Lex"],"categories":null,"content":"","date":1568073600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1568073600,"objectID":"f90a6c31c8623eaa455c1280844afac0","permalink":"https://tduricic.me/publication/2019_recsys/","publishdate":"2019-09-10T00:00:00Z","relpermalink":"/publication/2019_recsys/","section":"publication","summary":"In this work, we present the findings of an online study, where we explore the impact of utilizing embeddings to recommend job postings under real-time constraints. On the Austrian job platform Studo Jobs, we evaluate two popular recommendation scenarios - (i) providing similar jobs and, (ii) personalizing the job postings that are shown on the homepage. Our results show that for recommending similar jobs, we achieve the best online performance in terms of Click-Through Rate when we employ embeddings based on the most recent interaction. To personalize the job postings shown on a user's homepage, however, combining embeddings based on the frequency and recency with which a user interacts with job postings results in the best online performance.","tags":["Recommender Systems","Embeddings","Real-Time Analytics","Job Matching","Online Evaluation","User Modeling","Machine Learning"],"title":"Should we embed? A study on the online performance of utilizing embeddings for real-time job recommendations","type":"publication"},{"authors":null,"categories":null,"content":"Wowchemy is designed to give technical content creators a seamless experience. You can focus on the content and Wowchemy handles the rest.\nHighlight your code snippets, take notes on math classes, and draw diagrams from textual representation.\nOn this page, you‚Äôll find some examples of the types of technical content that can be rendered with Wowchemy.\nExamples Code Wowchemy supports a Markdown extension for highlighting code syntax. You can customize the styles under the syntax_highlighter option in your config/_default/params.yaml file.\n```python\rimport pandas as pd\rdata = pd.read_csv(\u0026#34;data.csv\u0026#34;)\rdata.head()\r```\rrenders as\nimport pandas as pd data = pd.read_csv(\u0026#34;data.csv\u0026#34;) data.head() Mindmaps Wowchemy supports a Markdown extension for mindmaps.\nSimply insert a Markdown markmap code block and optionally set the height of the mindmap as shown in the example below.\nA simple mindmap defined as a Markdown list:\n```markmap {height=\u0026#34;200px\u0026#34;}\r- Hugo Modules\r- wowchemy\r- wowchemy-plugins-netlify\r- wowchemy-plugins-netlify-cms\r- wowchemy-plugins-reveal\r```\rrenders as\n- Hugo Modules\r- wowchemy\r- wowchemy-plugins-netlify\r- wowchemy-plugins-netlify-cms\r- wowchemy-plugins-reveal A more advanced mindmap with formatting, code blocks, and math:\n```markmap\r- Mindmaps\r- Links\r- [Wowchemy Docs](https://wowchemy.com/docs/)\r- [Discord Community](https://discord.gg/z8wNYzb)\r- [GitHub](https://github.com/wowchemy/wowchemy-hugo-themes)\r- Features\r- Markdown formatting\r- **inline** ~~text~~ *styles*\r- multiline\rtext\r- `inline code`\r-\r```js\rconsole.log(\u0026#39;hello\u0026#39;);\rconsole.log(\u0026#39;code block\u0026#39;);\r```\r- Math: $x = {-b \\pm \\sqrt{b^2-4ac} \\over 2a}$\r```\rrenders as\n- Mindmaps\r- Links\r- [Wowchemy Docs](https://wowchemy.com/docs/)\r- [Discord Community](https://discord.gg/z8wNYzb)\r- [GitHub](https://github.com/wowchemy/wowchemy-hugo-themes)\r- Features\r- Markdown formatting\r- **inline** ~~text~~ *styles*\r- multiline\rtext\r- `inline code`\r-\r```js\rconsole.log(\u0026#39;hello\u0026#39;);\rconsole.log(\u0026#39;code block\u0026#39;);\r```\r- Math: $x = {-b \\pm \\sqrt{b^2-4ac} \\over 2a}$ Charts Wowchemy supports the popular Plotly format for interactive charts.\nSave your Plotly JSON in your page folder, for example line-chart.json, and then add the {{\u0026lt; chart data=\u0026#34;line-chart\u0026#34; \u0026gt;}} shortcode where you would like the chart to appear.\nDemo:\nYou might also find the Plotly JSON Editor useful.\nMath Wowchemy supports a Markdown extension for $\\LaTeX$ math. You can enable this feature by toggling the math option in your config/_default/params.yaml file.\nTo render inline or block math, wrap your LaTeX math with {{\u0026lt; math \u0026gt;}}$...${{\u0026lt; /math \u0026gt;}} or {{\u0026lt; math \u0026gt;}}$$...$${{\u0026lt; /math \u0026gt;}}, respectively. (We wrap the LaTeX math in the Wowchemy math shortcode to prevent Hugo rendering our math as Markdown. The math shortcode is new in v5.5-dev.)\nExample math block:\n{{\u0026lt; math \u0026gt;}} $$ \\gamma_{n} = \\frac{ \\left | \\left (\\mathbf x_{n} - \\mathbf x_{n-1} \\right )^T \\left [\\nabla F (\\mathbf x_{n}) - \\nabla F (\\mathbf x_{n-1}) \\right ] \\right |}{\\left \\|\\nabla F(\\mathbf{x}_{n}) - \\nabla F(\\mathbf{x}_{n-1}) \\right \\|^2} $$ {{\u0026lt; /math \u0026gt;}} renders as\n$$\\gamma_{n} = \\frac{ \\left | \\left (\\mathbf x_{n} - \\mathbf x_{n-1} \\right )^T \\left [\\nabla F (\\mathbf x_{n}) - \\nabla F (\\mathbf x_{n-1}) \\right ] \\right |}{\\left \\|\\nabla F(\\mathbf{x}_{n}) - \\nabla F(\\mathbf{x}_{n-1}) \\right \\|^2}$$\rExample inline math {{\u0026lt; math \u0026gt;}}$\\nabla F(\\mathbf{x}_{n})${{\u0026lt; /math \u0026gt;}} renders as $\\nabla F(\\mathbf{x}_{n})$.\nExample multi-line math using the math linebreak (\\\\):\n{{\u0026lt; math \u0026gt;}} $$f(k;p_{0}^{*}) = \\begin{cases}p_{0}^{*} \u0026amp; \\text{if }k=1, \\\\ 1-p_{0}^{*} \u0026amp; \\text{if }k=0.\\end{cases}$$ {{\u0026lt; /math \u0026gt;}} renders as\n$$\rf(k;p_{0}^{*}) = \\begin{cases}p_{0}^{*} \u0026amp; \\text{if }k=1, \\\\\r1-p_{0}^{*} \u0026amp; \\text{if }k=0.\\end{cases}\r$$\rDiagrams Wowchemy supports a Markdown extension for diagrams. You can enable this feature by toggling the diagram option in your config/_default/params.toml file or by adding diagram: true to your page front matter.\nAn example flowchart:\n```mermaid\rgraph TD\rA[Hard] --\u0026gt;|Text| B(Round)\rB --\u0026gt; C{Decision}\rC --\u0026gt;|One| D[Result 1]\rC --\u0026gt;|Two| E[Result 2]\r```\rrenders as\ngraph TD\rA[Hard] --\u0026gt;|Text| B(Round)\rB --\u0026gt; C{Decision}\rC --\u0026gt;|One| D[Result 1]\rC --\u0026gt;|Two| E[Result 2] An example sequence diagram:\n```mermaid\rsequenceDiagram\rAlice-\u0026gt;\u0026gt;John: Hello John, how are you?\rloop Healthcheck\rJohn-\u0026gt;\u0026gt;John: Fight against hypochondria\rend\rNote right of John: Rational thoughts!\rJohn--\u0026gt;\u0026gt;Alice: Great!\rJohn-\u0026gt;\u0026gt;Bob: How about you?\rBob--\u0026gt;\u0026gt;John: Jolly good!\r```\rrenders as\nsequenceDiagram\rAlice-\u0026gt;\u0026gt;John: Hello John, how are you?\rloop Healthcheck\rJohn-\u0026gt;\u0026gt;John: Fight against hypochondria\rend\rNote right of John: Rational thoughts!\rJohn--\u0026gt;\u0026gt;Alice: Great!\rJohn-\u0026gt;\u0026gt;Bob: How about you?\rBob--\u0026gt;\u0026gt;John: Jolly good! An example Gantt diagram:\n```mermaid\rgantt\rsection Section\rCompleted :done, des1, 2014-01-06,2014-01-08\rActive :active, des2, 2014-01-07, 3d\rParallel 1 : des3, after des1, 1d\rParallel 2 : des4, after des1, 1d\rParallel 3 : des5, after des3, 1d\rParallel 4 : des6, after des4, 1d\r```\rrenders ‚Ä¶","date":1562889600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1562889600,"objectID":"07e02bccc368a192a0c76c44918396c3","permalink":"https://tduricic.me/post/writing-technical-content/","publishdate":"2019-07-12T00:00:00Z","relpermalink":"/post/writing-technical-content/","section":"post","summary":"Wowchemy is designed to give technical content creators a seamless experience. You can focus on the content and Wowchemy handles the rest.\nHighlight your code snippets, take notes on math classes, and draw diagrams from textual representation.","tags":null,"title":"Writing technical content in Markdown","type":"post"},{"authors":["Tomislav ƒêuriƒçiƒá","Emanuel Laciƒá","Dominik Kowald","Elisabeth Lex"],"categories":null,"content":"","date":1560297600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1560297600,"objectID":"f73eecf4ccbc55c11fb28dad860dcbf3","permalink":"https://tduricic.me/publication/2019_eurocss/","publishdate":"2019-06-12T00:00:00Z","relpermalink":"/publication/2019_eurocss/","section":"publication","summary":"This study explores using regular equivalence in trust networks to improve Collaborative Filtering recommendations, particularly for cold-start users. While traditional CF suffers from data sparsity when users rate few items, incorporating trust relationships (explicit or implicit) can enhance recommendations. The research applies an iterative regular equivalence calculation to generate similarity matrices for neighbor selection, examining how both strong and weak network ties affect recommendation quality. Evaluations on Epinions data demonstrate that incorporating weak ties alongside strong ties significantly improves recommendation accuracy for cold-start users in trust-based recommender systems.","tags":["Recommender Systems","Trust Networks","Weak Ties","Network Theory","Regular Equivalence","Collaborative Filtering","Machine Learning"],"title":"Exploiting weak ties in trust-based recommender systems using regular equivalence","type":"publication"},{"authors":["Tomislav ƒêuriƒçiƒá"],"categories":[],"content":"from IPython.core.display import Image Image(\u0026#39;https://www.python.org/static/community_logos/python-logo-master-v3-TM-flattened.png\u0026#39;) print(\u0026#34;Welcome to Academic!\u0026#34;) Welcome to Academic!\rInstall Python and JupyterLab Install Anaconda which includes Python 3 and JupyterLab.\nAlternatively, install JupyterLab with pip3 install jupyterlab.\nCreate or upload a Jupyter notebook Run the following commands in your Terminal, substituting \u0026lt;MY-WEBSITE-FOLDER\u0026gt; and \u0026lt;SHORT-POST-TITLE\u0026gt; with the file path to your Academic website folder and a short title for your blog post (use hyphens instead of spaces), respectively:\nmkdir -p \u0026lt;MY-WEBSITE-FOLDER\u0026gt;/content/post/\u0026lt;SHORT-POST-TITLE\u0026gt;/ cd \u0026lt;MY-WEBSITE-FOLDER\u0026gt;/content/post/\u0026lt;SHORT-POST-TITLE\u0026gt;/ jupyter lab index.ipynb The jupyter command above will launch the JupyterLab editor, allowing us to add Academic metadata and write the content.\nEdit your post metadata The first cell of your Jupter notebook will contain your post metadata (front matter).\nIn Jupter, choose Markdown as the type of the first cell and wrap your Academic metadata in three dashes, indicating that it is YAML front matter:\n--- title: My post\u0026#39;s title date: 2019-09-01 # Put any other Academic metadata here... --- Edit the metadata of your post, using the documentation as a guide to the available options.\nTo set a featured image, place an image named featured into your post‚Äôs folder.\nFor other tips, such as using math, see the guide on writing content with Academic.\nConvert notebook to Markdown jupyter nbconvert index.ipynb --to markdown --NbConvertApp.output_files_dir=. Example This post was created with Jupyter. The orginal files can be found at https://github.com/gcushen/hugo-academic/tree/master/exampleSite/content/post/jupyter\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1567641600,"objectID":"6e929dc84ed3ef80467b02e64cd2ed64","permalink":"https://tduricic.me/post/jupyter/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/post/jupyter/","section":"post","summary":"Learn how to blog in Academic using Jupyter notebooks","tags":[],"title":"Display Jupyter Notebooks with Academic","type":"post"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Wowchemy Wowchemy | Documentation\nFeatures Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides Controls Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026#34;blueberry\u0026#34; if porridge == \u0026#34;blueberry\u0026#34;: print(\u0026#34;Eating...\u0026#34;) Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nFragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}} Press Space to play!\nOne Two Three A fragment can accept two optional parameters:\nclass: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}} Press the S key to view the speaker notes!\nOnly the speaker can read these notes Press S key to view Themes black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026#34;/media/boards.jpg\u0026#34; \u0026gt;}} {{\u0026lt; slide background-color=\u0026#34;#0000FF\u0026#34; \u0026gt;}} {{\u0026lt; slide class=\u0026#34;my-style\u0026#34; \u0026gt;}} Custom CSS Example Let‚Äôs make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; } Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"https://tduricic.me/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Wowchemy's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":["Tomislav ƒêuriƒçiƒá","Emanuel Laciƒá","Dominik Kowald","Elisabeth Lex"],"categories":null,"content":"","date":1538006400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1538006400,"objectID":"89b6491ec89dff60e39fbf842f71505a","permalink":"https://tduricic.me/publication/2018_recsys/","publishdate":"2018-09-27T00:00:00Z","relpermalink":"/publication/2018_recsys/","section":"publication","summary":"This study uses regular equivalence in trust networks to improve recommendations for cold-start users in Collaborative Filtering systems. By applying this network science measure to user trust relationships, the researchers create a similarity matrix that helps select better user neighbors for recommendation purposes. Testing on the Epinions dataset shows their approach outperforms related methods in recommendation accuracy for new users with few ratings.","tags":["Recommender Systems","Trust Networks","Cold-Start Problem","Collaborative Filtering","Regular Equivalence","Network Analysis","Machine Learning"],"title":"Trust-based collaborative filtering: tackling the cold start problem using regular equivalence","type":"publication"},{"authors":null,"categories":null,"content":"Project Overview (August 2018 ‚Äì June 2019) At Know Center Research, we collaborated with Land Nieder√∂sterreich to create a personalized recommendation solution for the ‚ÄúVirtual House of Digitalization‚Äù (Virtuelles Haus der Digitalisierung - VHDD). This initiative aimed at providing personalized digitalization services to SMEs and experts through a virtual platform, later extended into the physical House of Digitalization in Tulln, Lower Austria.\nThe platform offers personalized resource recommendations and matchmaking services to help businesses and individuals find relevant information, partners, and digitalization tools efficiently. Following the initial successful phase, the project was extended by three months with a smaller follow-up initiative.\nTechnical Challenges Developing real-time personalized recommendations for diverse content types (events, projects, partners, and resources) Integrating recommender system seamlessly within the VHDD platform infrastructure Addressing cold-start and data sparsity problems in matchmaking and resource recommendations Managing and coordinating internal team efforts and external partner communications Technologies \u0026amp; Methods Core Development: Java, Apache Solr, Spring Boot, Microservices Architecture, ScaR recommender system Data Management: CRUD services, Apache Solr indexing and search Recommendation Algorithms: Content-Based Filtering, Collaborative Filtering, Popularity-based approaches Evaluation \u0026amp; Deployment: Real-time recommendation evaluation, continuous integration and deployment, Docker-based infrastructure Results \u0026amp; Impact Successfully deployed multiple personalized recommendation use cases including matchmaking and resource recommendation Enhanced user engagement and content discoverability significantly within the VHDD platform Provided SMEs with an effective tool for digitalization services exploration and matchmaking Personal Contribution Managed a team of three (including myself), covering software engineering, data science, and project management tasks Coordinated communication and collaboration between Know Center Research, external partners, and clients Contributed actively to software engineering, ML algorithm development, and recommendation solution integration Ensured timely delivery and successful deployment of project deliverables, leading to high client satisfaction ","date":1533081600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1533081600,"objectID":"7152acf1da980773760db8bfdd795c25","permalink":"https://tduricic.me/project/vhdd/","publishdate":"2018-08-01T00:00:00Z","relpermalink":"/project/vhdd/","section":"project","summary":"Successfully developed and deployed multiple personalized content recommendation use cases using the ScaR recommender framework for the Virtual House of Digitalization, enhancing content discovery and user engagement.","tags":["Recommender Systems","Matchmaking","Resource Recommendation","Real-Time Recommendations","Data Pipeline","Microservices","Project Management","User Behavior"],"title":"Virtuelles Haus der Digitalisierung (VHDD)","type":"project"},{"authors":["Emanuel Laciƒá","Matthias Traub","Tomislav ƒêuriƒçiƒá","Eva Haslauer","Elisabeth Lex"],"categories":null,"content":"","date":1532736000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1532736000,"objectID":"e6cad5f326f5b6cbe179da6af80c3d8a","permalink":"https://tduricic.me/publication/2018_it/","publishdate":"2018-07-28T00:00:00Z","relpermalink":"/publication/2018_it/","section":"publication","summary":"A challenge for importers in the automobile industry is adjusting to rapidly changing market demands. In this work, we describe a practical study of car import planning based on the monthly car registrations in Austria. We model the task as a data driven forecasting problem and we implement four different prediction approaches. One utilizes a seasonal ARIMA model, while the other is based on LSTM-RNN and both compared to a linear and seasonal baselines. In our experiments, we evaluate the 33 different brands by predicting the number of registrations for the next month and for the year to come.","tags":["Time-Series Analysis","Demand Forecasting","LSTM","SARIMA","Automotive Industry","Predictive Analytics"],"title":"Gone in 30 days! Predictions for car import planning","type":"publication"},{"authors":null,"categories":null,"content":"Project Overview (June 2017 ‚Äì September 2019) At Know Center Research, we partnered with Studo, a widely-used student app in Germany and Austria, to develop a personalized recommender system for their job listings feature. The successful solution later evolved into the dedicated platform ‚ÄúTalto ‚Äì Talents of Tomorrow,‚Äù significantly enhancing the student job application process through intelligent matchmaking.\nThe initial project phase (‚ÄúStudo Matchmaking Recommender ‚Äì Empfehlungs Plattform personalisierter Job Anzeigen f√ºr Studenten‚Äù) ran from June 2017 to May 2018. Following its success, we secured additional funding from the Austrian Research Promotion Agency (FFG) for the follow-up project (‚ÄúFAT ‚Äì Fair, Accountable \u0026amp; Transparent Matchmaking: Explainability, Sessions, Scoring and Biases for Passive Sourcing‚Äù), which took place from October 2018 to September 2019.\nTechnical Challenges Defining meaningful and varied recommender use-cases for student-job matchmaking Developing custom real-time recommender algorithms to handle diverse data and contexts Ensuring scalability and seamless integration into the Studo app infrastructure Addressing fairness, transparency, and explainability in recommendations Technologies \u0026amp; Methods Core Development: Java, Apache Solr, Microservices with ScaR recommender framework Machine Learning \u0026amp; Algorithms: Python, Doc2Vec embeddings, Autoencoders, Vector Search Deployment \u0026amp; Testing: Docker, Continuous Integration, Extensive Testing Research \u0026amp; Documentation: Scientific publication writing, comprehensive documentation Results \u0026amp; Impact Improved user engagement with the Studo job marketplace (~20% increase) Increased application rate to job postings (~18% increase) Conducted pioneering research on matchmaking algorithms tailored for student and graduate job markets Enabled high-quality personalization even for anonymous users and additional content recommendations (e.g., news articles) Produced multiple impactful academic publications Featured as an FFG success story (full story here) Selected Publications @article{lacic2017beyond, title={Beyond accuracy optimization: On the value of item embeddings for student job recommendations}, author={Lacic, Emanuel and Kowald, Dominik and Reiter-Haas, Markus and Slawicek, Valentin and Lex, Elisabeth}, journal={arXiv preprint arXiv:1711.07762}, year={2017} } @inproceedings{reiter2017studo, title={Studo Jobs: Enriching Data With Predicted Job Labels}, author={Reiter-Haas, Markus and Slawicek, Valentin and Lacic, Emanuel}, booktitle={CEUR Workshop Proceedings}, volume={2025}, year={2017}, organization={RWTH Aachen} } @inproceedings{lacic2019should, title={Should we embed? A study on the online performance of utilizing embeddings for real-time job recommendations}, author={Lacic, Emanuel and Reiter-Haas, Markus and Duricic, Tomislav and Slawicek, Valentin and Lex, Elisabeth}, booktitle={Proceedings of the 13th ACM conference on recommender systems}, pages={496--500}, year={2019} } @article{lacic2020using, title={Using autoencoders for session-based job recommendations}, author={Lacic, Emanuel and Reiter-Haas, Markus and Kowald, Dominik and Reddy Dareddy, Manoj and Cho, Junghoo and Lex, Elisabeth}, journal={User Modeling and User-Adapted Interaction}, volume={30}, pages={617--658}, year={2020}, publisher={Springer} } @inproceedings{reiter2020heterogeneous, title={On the heterogeneous information needs in the job domain: A unified platform for student career}, author={Reiter-Haas, Markus and Wittenbrink, David and Lacic, Emanuel}, booktitle={Proceedings of the 14th ACM Conference on Recommender Systems}, pages={573--574}, year={2020} } Personal Contribution Managed a team of five, overseeing project execution, requirements engineering, and budget planning Actively contributed as a Software Engineer, ML Engineer, and Data Scientist to the development and implementation of recommender algorithms Coordinated deployment and continuous improvement of the platform Authored academic publications and secured additional project funding from FFG Co-advised academic work including one Master‚Äôs thesis and supported the onboarding of one PhD student ","date":1496275200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1496275200,"objectID":"1f83562581901404b7772055a7aa5cfa","permalink":"https://tduricic.me/project/studo/","publishdate":"2017-06-01T00:00:00Z","relpermalink":"/project/studo/","section":"project","summary":"Developed and deployed a personalized job matchmaking recommender system for Studo, later spun off into the standalone platform Talto, significantly enhancing student engagement and job application rates.","tags":["Recommender Systems","Matchmaking","Machine Learning","Real-Time Recommendations","Data Pipeline","Vector Search","Project Management","User Modeling","Embeddings"],"title":"Studo/Talto Job Matchmaking Platform","type":"project"},{"authors":null,"categories":null,"content":"Project Overview (July 2016 ‚Äì July 2018) At Know Center Research, we collaborated with Porsche Holding GmbH (Porsche Holding Salzburg), Europe‚Äôs largest automotive distributor, representing Volkswagen Group brands in wholesale, retail, and after-sales services. Porsche sought an accurate time-series prediction solution to optimize monthly car orders based on historical sales data.\nTechnical Challenges Key challenges faced in this project included:\nHandling large and varied time-series datasets Performing thorough data cleaning and exploratory analysis Conducting comprehensive hyperparameter optimization Implementing accurate linear and non-linear predictive models Technologies \u0026amp; Methods The solution was built using advanced data analytics and visualization tools:\nMachine Learning \u0026amp; Analysis: Python, R, ARIMA, SARIMA, LSTM neural networks (Keras) Data Visualization \u0026amp; Dashboard: Interactive dashboards using Plotly Data Exploration \u0026amp; Cleaning: Extensive data preprocessing, feature engineering, and exploratory data analysis (EDA) Research \u0026amp; Publication: Scientific publication highlighting methodology and results Results \u0026amp; Impact Delivered an end-to-end predictive analytics dashboard integrated into Porsche Holding‚Äôs operational processes Improved accuracy in predicting monthly car order requirements Recognized internally with the company‚Äôs Project Excellence Silver Award Successfully collaborated on a research publication titled ‚ÄúGone in 30 days! Predictions for car import planning‚Äù in the journal Information Technology Featured as a success story in Austria‚Äôs Trend magazine Personal Contribution As a Software Engineer, ML Engineer, and Data Scientist, my responsibilities included:\nDeveloping the complete data processing and cleaning pipeline Conducting extensive data exploration and feature engineering Researching and implementing linear and non-linear time-series predictive models (ARIMA, SARIMA, LSTM) Creating interactive visualizations and predictive analytics dashboards with Plotly Co-authoring the research publication and presenting ","date":1467331200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1467331200,"objectID":"0ee5010ab1a24424efdf7a78f1b900e7","permalink":"https://tduricic.me/project/porsche/","publishdate":"2016-07-01T00:00:00Z","relpermalink":"/project/porsche/","section":"project","summary":"Developed a data-driven time-series prediction dashboard for Porsche Holding Salzburg, optimizing monthly car order volumes using Python, R, Plotly, ARIMA, SARIMA, and LSTM (Keras).","tags":["Machine Learning","Time-Series Analysis","Data Visualization","Dashboard Development","Predictive Analytics","Automotive"],"title":"Porsche Holding Demand Prediction Dashboard","type":"project"},{"authors":null,"categories":null,"content":"Project Overview (June 2016 ‚Äì December 2016) At Know Center Research, we collaborated with with Detego Fashion who leverage patented RFID technology to track garments from manufacturing through retail, enhancing inventory accuracy and customer experience. Fashion brands including Levi‚Äôs, Adidas, and Reiss use this technology for in-store tracking, real-time stock visibility, and online order fulfillment. Our task was to implement a real-time outlier detection system to optimize garment placement within retail stores, boosting sales for low-performing items.\nTechnical Challenges Key challenges included:\nDesigning a reliable, real-time data processing pipeline Ensuring robust and accurate data cleaning and preprocessing Integrating an effective outlier detection algorithm capable of handling retail data complexity Technologies \u0026amp; Methods The solution integrated multiple technologies and methods:\nArchitecture: Microservices with Java, Spring Boot, Swagger, RabbitMQ Data Storage: Apache Solr for data indexing and retrieval Machine Learning \u0026amp; Analysis: Python (numpy, pandas, sklearn, scipy) for outlier detection using Mahalanobis distance Data Processing: Java-based real-time data pipeline, integration with Python scripts for data analysis CI/CD \u0026amp; Testing: Extensive testing (JUnit, integration tests), Agile development methodology Deployment: Production-ready solution deployed in a retail environment Results \u0026amp; Impact Delivered a fully operational real-time outlier detection pipeline Enabled automated and intelligent decision-making for garment placement Enhanced sales performance by optimizing store layouts and merchandising Featured as a success story in Austria‚Äôs Trend magazine Personal Contribution As a Software Engineer and ML Engineer on this project, my responsibilities included:\nDesigning and developing the end-to-end data processing pipeline in Java Integrating and orchestrating the real-time execution of the outlier detection algorithm developed by a colleague in Python Ensuring seamless communication between microservices and the Python components Conducting extensive testing and validation to ensure reliable, accurate predictions Deploying and maintaining the solution in production environments The project was recognized as a notable industry success and was featured in the Austrian Trend magazine.\n","date":1464739200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1464739200,"objectID":"c755ad85d7203bebc2b9fa3f14b01af5","permalink":"https://tduricic.me/project/detego/","publishdate":"2016-06-01T00:00:00Z","relpermalink":"/project/detego/","section":"project","summary":"Developed a real-time data pipeline and integrated an outlier detection system to optimize garment placement in retail stores, improving sales performance. Built with Java, Spring Boot, RabbitMQ, Apache Solr, Python, and sklearn.","tags":["Machine Learning","Data Pipeline","Outlier Detection","Real-Time Processing","Retail Analytics","Recommender Systems","Real-Time Recommendations"],"title":"Detego Fashion Outlier Detection","type":"project"},{"authors":null,"categories":null,"content":"Project Overview (March 2016 ‚Äì December 2016) At Know Center Research, I developed a machine learning system for a digital photo printing company. The system intelligently assigned user-uploaded images to appropriate calendar months, significantly enhancing the user experience by automating photo selection.\nQuick Highlights:\nEnd-to-end ML pipeline analyzing image metadata Technologies: Java, Spring Boot, RabbitMQ, Apache Solr, PySpark, Weka Achieved substantial accuracy improvements over manual/random assignments Scalable solution suitable for production workloads Technical Challenges Key challenges addressed included:\nDesigning a scalable microservices architecture for image processing Extracting and analyzing relevant image metadata efficiently Developing accurate predictive models for assigning images to calendar months Establishing a robust, scalable data pipeline Technologies \u0026amp; Methods The solution leveraged various technologies and approaches:\nArchitecture: Microservices using Java 8, Spring Boot, Swagger, and RabbitMQ Data Storage: Apache Solr for efficient metadata indexing and retrieval Machine Learning: Weka (J48, Random Forest, Naive Bayes classifiers) Data Processing: PySpark, HDFS, Hadoop, and Python for large-scale analysis and visualization CI/CD: Jenkins, Maven, Git, JUnit, and integration testing for quality assurance Development: IntelliJ IDEA, Agile methodology with Scrum Results \u0026amp; Impact Significantly improved accuracy in month assignment compared to manual/random assignments Robust handling of images with incomplete metadata Enhanced user experience through streamlined calendar creation Delivered a scalable, reliable system capable of production deployment Personal Contribution As the primary developer on this project, I:\nDesigned and implemented the data extraction pipeline Conducted feature engineering and classifier evaluations using Weka Performed large-scale data analysis using PySpark and Hadoop Developed scalable microservices architecture adhering to industry best practices Created comprehensive test suites (JUnit, integration tests) Authored detailed project documentation ","date":1456790400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1456790400,"objectID":"f0bb4dd1199322ef8521d7555b345d4a","permalink":"https://tduricic.me/project/ifolor/","publishdate":"2016-03-01T00:00:00Z","relpermalink":"/project/ifolor/","section":"project","summary":"Developed an end-to-end machine learning pipeline that analyzes image metadata to intelligently assign photos to calendar months. Built with Java 8, Spring Boot, RabbitMQ, Apache Solr, Maven, and Jenkins CI/CD. Implemented data processing with PySpark, HDFS, and Hadoop. Created machine learning models using Weka with JUnit and integration testing for quality assurance.","tags":["Machine Learning","Supervised Learning","Classification","Data Pipeline","Recommender Systems","Image Analysis"],"title":"Photo Calendar Recommendation System","type":"project"},{"authors":null,"categories":null,"content":"Project Overview (March 2015 ‚Äì December 2020, ongoing occasionally) At Know Center Research, I have extensively contributed to ScaR (Scalable Recommender), our in-house recommender framework designed for real-time, scalable, and context-aware recommendation scenarios. ScaR follows a microservices architecture, integrating seamlessly with streaming data to provide immediate recommendations without costly recalculations. More information about ScaR is available on the official project website.\nKey Projects Using ScaR Master‚Äôs thesis on social-based recommendation algorithms Student job matchmaking in collaboration with Studo Matchmaking on the VHDD platform Personalized learning content recommendations in the Cogsteps project Adaptive conference session recommendations with Conference Navigator Technical Challenges Immediate processing of high-frequency streaming data Scalability in cloud-based and distributed environments Integration of diverse recommendation algorithms Real-time updates without performance degradation Technologies \u0026amp; Methods Core Development: Java, Apache Solr, Spring Boot, Microservices Architecture Data Management \u0026amp; Processing: Real-time data ingestion and handling using Apache Solr‚Äôs near-real-time features Continuous Integration \u0026amp; Deployment: Jenkins, Maven, Docker, Apache ZooKeeper Recommendation Algorithms: Content-Based Filtering, Collaborative Filtering, Hybrid Approaches Testing \u0026amp; Maintenance: JUnit, comprehensive unit, and integration testing Results \u0026amp; Impact Enabled multiple successful commercial and research projects Improved recommendation accuracy and speed across various use cases Featured in many academic publications, with the main reference: @inproceedings{lacic2015scar, title={Scar: Towards a real-time recommender framework following the microservices architecture}, author={Lacic, Emanuel and Traub, Matthias and Kowald, Dominik and Lex, Elisabeth}, booktitle={Proceedings of the Workshop on Large Scale Recommender Systems (LSRS2015) at RecSys}, pages={16--20}, year={2015} } Personal Contribution Acted as a core contributor, significantly influencing the framework‚Äôs features and development Implemented and tested various recommendation algorithms within ScaR Integrated ScaR into multiple industry and academic projects Assisted with maintenance, deployment, and infrastructure improvements for enhanced scalability and reliability ","date":1425168000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1425168000,"objectID":"9d9142b3fd8c1261cbaec68f089373c3","permalink":"https://tduricic.me/project/scar/","publishdate":"2015-03-01T00:00:00Z","relpermalink":"/project/scar/","section":"project","summary":"Core contributor to ScaR, an in-house scalable recommender framework following the microservices architecture, supporting real-time recommendations and streaming data processing using Java, Apache Solr, Spring Boot, Docker, and Jenkins.","tags":["Recommender Systems","Microservices","Real-Time Analytics","Data Streaming","Data Pipeline","Real-Time Recommendations","User Modeling","API"],"title":"ScaR: Real-Time Recommender Framework","type":"project"}]